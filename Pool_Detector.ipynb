{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Pool Detector</h1>\n",
    "<h2 align=\"center\">A problem of Quera's Olympic of Technology in Image and Data Processing </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "On many tourism and accommodation booking websites, users can view various images of different properties. In this project, we aim to design a model that can predict the presence or absence of a swimming pool in an accommodation based on the analysis of its images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from PIL import Image"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.024125Z",
     "start_time": "2025-10-01T15:13:48.014388Z"
    }
   },
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "source": [
    "# Check for GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU is available: {gpus}\")\n",
    "    try:\n",
    "        # Set TensorFlow to use only the first GPU\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"GPU not available.\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.118620Z",
     "start_time": "2025-10-01T15:13:48.102597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Introduction\n",
    "\n",
    "The provided dataset is in JSON format and contains information about 1,599 accommodations. The main key is \"rooms\", which holds a list of all properties. Each record represents an accommodation with its specific features and amenities. The table below describes the keys for each record:\n",
    "\n",
    "| Key          | Description                                    |\n",
    "|:-------------|:-----------------------------------------------|\n",
    "| `id`         | Unique identifier for the accommodation        |\n",
    "| `title`      | Title of the accommodation listing             |\n",
    "| `description`| A detailed description of the accommodation    |\n",
    "| `province`   | Province information, including ID and name    |\n",
    "| `city`       | City information, including ID and name        |\n",
    "\n",
    "Here is an example of a single data entry:\n",
    "```json\n",
    "{\n",
    "  \"rooms\": [\n",
    "    {\n",
    "      \"id\": 3202100,\n",
    "      \"title\": \"Rent a suite on Javaherdeh road - Ashkounkooh\",\n",
    "      \"description\": \"This suite with no bedroom features a lovely balcony and a beautiful view, located on the ground floor of a two-story building. The distance to the supermarket and bakery is about 50 and 500 meters, respectively.\",\n",
    "      \"province\": {\n",
    "        \"id\": \"p26\",\n",
    "        \"name\": \"Mazandaran\"\n",
    "      },\n",
    "      \"city\": {\n",
    "        \"id\": 303,\n",
    "        \"name\": \"Ramsar\"\n",
    "      }\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "\n",
    "First, you need to read the dataset files. The training features are in `train.json`, and the test data (used to find image directories) is in `test.json`. The image directory for each accommodation corresponds to its `id` and is located inside the `pictures` folder.\n",
    "\n",
    "**Note:** The dataset is approximately 3.8 GB. If you have trouble uploading it to your environment (like Google Colab), you can use the code below to download and unzip it directly.\n",
    "\n",
    "<a href=\"https://drive.google.com/file/d/1b8O_a6ywcsbLqJAGDGCkePrdn1cFlXl0/view?usp=sharing\" target=\"_blank\">Download from Google Drive</a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Run this cell to download the data directly into your environment\n",
    "\n",
    "# Install gdown to download from Google Drive\n",
    "# !pip install gdown\n",
    "# \n",
    "# import gdown\n",
    "# import zipfile\n",
    "# \n",
    "# # Google Drive file ID and destination filename\n",
    "# file_id = '1b8O_a6ywcsbLqJAGDGCkePrdn1cFlXl0'\n",
    "# destination = 'dataset.zip'\n",
    "# \n",
    "# # Download the file\n",
    "# gdown.download(f'https://drive.google.com/uc?id={file_id}', destination, quiet=False)\n",
    "# \n",
    "# # Unzip the file\n",
    "# with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
    "#     zip_ref.extractall('unzipped_content')\n",
    "# \n",
    "# print(\"Download and extraction complete.\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.134383Z",
     "start_time": "2025-10-01T15:13:48.120531Z"
    }
   },
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.150029Z",
     "start_time": "2025-10-01T15:13:48.134383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_json_path = 'unzipped_content/train.json'\n",
    "test_json_path = 'unzipped_content/test.json'"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.165453Z",
     "start_time": "2025-10-01T15:13:48.150029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Run this cell if you are on colab\n",
    "\n",
    "# train_json_path = os.path.join(\"content/\", train_json_path)\n",
    "# test_json_path = os.path.join(\"content/\", test_json_path)"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = pd.read_json(train_json_path)\n",
    "print(\"Sample training data entry:\")\n",
    "print(train_data[\"rooms\"][0])"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.213007Z",
     "start_time": "2025-10-01T15:13:48.165453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training data entry:\n",
      "{'id': 3175858, 'title': 'رزرو ویلا با استخر روباز آبگرم در چهارباغ', 'description': '**رزرو ویلا با استخر روباز آبگرم در چهارباغ **\\nاین ویلا دو خوابه که یک اتاق خواب مستر دارد با استخر چهارفصل روباز آبگرم در حیاط دنج و باصفای ویلا مزین به آبنما، فضای سبز، آتشدان و باربیکیو در منطقه ای امن و آرام از چهارباغ واقع شده است و با شهر کرج حدود ۲۵ کیلومتر فاصله دارد.\\nبام تهرانی موجود به همراه فضای حیاط دلنشین ویلا می تواند اوقات خوشی را جهت شب نشینی و بهره بردن از آب و هوای منطقه فراهم آورد.\\nمحیط اطراف ویلا از چهار طرف با دیوار بلند حصارکشی شده است و یک واحد نگهبانی شبانه در کانکس موجود در محوطه کوچه مستقر می باشد.\\nاز این ویلا با حدود ۳ دقیقه رانندگی دسترسی به نانوایی و سوپرمارکت امکان\\u200cپذیر است.\\nکیفیت خطوط شبکه برای ایرانسل و همراه اول در مکالمه عالی و پوشش اینترنت ۴g می باشد.\\nلازم به ذکر است حدود ۴۰۰ متر مسیر انتهایی ویلا جاده خاکی مناسب برای عبور و مرور وسایل نقلیه می باشد.', 'province': {'id': 'p31', 'name': 'البرز'}, 'city': {'id': 363, 'name': 'چهارباغ'}}\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "source": [
    "test_data = pd.read_json(test_json_path)\n",
    "print(\"Test data structure:\")\n",
    "print(test_data.head())"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.228714Z",
     "start_time": "2025-10-01T15:13:48.213007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data structure:\n",
      "             rooms\n",
      "0  {'id': 3160664}\n",
      "1  {'id': 3195184}\n",
      "2  {'id': 3224078}\n",
      "3  {'id': 3233712}\n",
      "4  {'id': 3201449}\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Engineering\n",
    "\n",
    "In this section, we will create the target labels for our model. We will determine if an accommodation has a pool by searching for the keyword `استخر` (Persian for \"pool\") in its `title` and `description`.\n",
    "\n",
    "The effectiveness of this feature engineering step directly impacts the model's performance. A well-created label set is crucial for training an accurate model."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.DataFrame()\n",
    "\n",
    "for i in train_data['rooms']:\n",
    "  # Check for the keyword \"استخر\" in both \"title\" and \"description\"\n",
    "  has_pool = \"استخر\" in i.get(\"title\", \"\") or \"استخر\" in i.get(\"description\", \"\")\n",
    "  i[\"pool\"] = has_pool\n",
    "  train_df = pd.concat([train_df, pd.DataFrame.from_records([{\"id\": i[\"id\"], 'pool': i[\"pool\"]}])])\n",
    "  \n",
    "print('\\nValue counts for the target variable:')\n",
    "print(train_df['pool'].value_counts())"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.591847Z",
     "start_time": "2025-10-01T15:13:48.228714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for the target variable:\n",
      "pool\n",
      "True     807\n",
      "False    792\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.607628Z",
     "start_time": "2025-10-01T15:13:48.591847Z"
    }
   },
   "cell_type": "code",
   "source": "train_df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         id   pool\n",
       "0   3175858   True\n",
       "0   3237321   True\n",
       "0   3154228   True\n",
       "0   3169850  False\n",
       "0   3207557  False\n",
       "..      ...    ...\n",
       "0   3167459   True\n",
       "0   3207406   True\n",
       "0   3172620  False\n",
       "0   3237948  False\n",
       "0   3229812  False\n",
       "\n",
       "[1599 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3175858</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3237321</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3154228</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3169850</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3207557</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3167459</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3207406</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3172620</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3237948</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3229812</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Images\n",
    "\n",
    "Now, we will load the images from their respective directories. We will create a list of all image paths and their corresponding labels (`True`/`False` for the presence of a pool)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.623373Z",
     "start_time": "2025-10-01T15:13:48.609649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_dir = 'unzipped_content/train'\n",
    "\n",
    "## Run this as well if you're on colab ##\n",
    "# image_dir = os.path.join(\"content/\", image_dir)\n",
    "# print(image_dir)"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "source": [
    "image_dir = os.path.join(os.getcwd(), \"unzipped_content/train\")\n",
    "\n",
    "all_locations = []\n",
    "for index, row in train_df.iterrows():\n",
    "    id = row['id']\n",
    "    pool_label = row['pool']\n",
    "    path = os.path.join(image_dir, str(id))\n",
    "    if os.path.exists(path):\n",
    "        one_location_img_files = os.listdir(path)\n",
    "        one_location_path = []\n",
    "        for img_path in one_location_img_files:\n",
    "            one_location_path.append(os.path.join(path, img_path))\n",
    "        single_location = []\n",
    "        single_location.append(id)\n",
    "        single_location.append(pool_label)\n",
    "        single_location.append(one_location_path)\n",
    "        all_locations.append(single_location)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.830319Z",
     "start_time": "2025-10-01T15:13:48.623373Z"
    }
   },
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.845791Z",
     "start_time": "2025-10-01T15:13:48.830319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_paths_labels = []\n",
    "for location_data in all_locations:\n",
    "    pool_label = location_data[1]\n",
    "    image_paths = location_data[2]\n",
    "    for image_path in image_paths:\n",
    "        image_paths_labels.append((image_path, pool_label))\n",
    "\n",
    "print(\"Number of image path and label pairs:\", len(image_paths_labels))\n",
    "print(\"First 5 pairs:\", image_paths_labels[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image path and label pairs: 15841\n",
      "First 5 pairs: [('C:\\\\Users\\\\Pouyan\\\\PycharmProjects\\\\Pool_Detector\\\\unzipped_content/train\\\\3175858\\\\3175858220912224333.jpg', True), ('C:\\\\Users\\\\Pouyan\\\\PycharmProjects\\\\Pool_Detector\\\\unzipped_content/train\\\\3175858\\\\3175858220912224711.jpg', True), ('C:\\\\Users\\\\Pouyan\\\\PycharmProjects\\\\Pool_Detector\\\\unzipped_content/train\\\\3175858\\\\3175858220912224834.jpg', True), ('C:\\\\Users\\\\Pouyan\\\\PycharmProjects\\\\Pool_Detector\\\\unzipped_content/train\\\\3175858\\\\3175858220912224844.jpg', True), ('C:\\\\Users\\\\Pouyan\\\\PycharmProjects\\\\Pool_Detector\\\\unzipped_content/train\\\\3175858\\\\3175858220912225459.jpg', True)]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a TensorFlow Dataset\n",
    "\n",
    "To train the model efficiently, we'll use `tf.data.Dataset`. This allows for high-performance data loading pipelines, including on-the-fly preprocessing, shuffling, and batching."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Separate paths and labels\n",
    "image_paths = [item[0] for item in image_paths_labels]\n",
    "labels = [item[1] for item in image_paths_labels]\n",
    "\n",
    "# Create TensorFlow datasets from the lists\n",
    "path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(labels, tf.int32))\n",
    "\n",
    "# Zip the paths and labels together\n",
    "full_ds = tf.data.Dataset.zip((path_ds, label_ds))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.893372Z",
     "start_time": "2025-10-01T15:13:48.845791Z"
    }
   },
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_image(image_path, label):\n",
    "    # Read the image file\n",
    "    img = tf.io.read_file(image_path)\n",
    "    # Decode the JPEG image to 3 channels (RGB)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Resize all images to a consistent size\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    # There is no need for normalization since we're going to use \"SELU\"\n",
    "    return img, label\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "processed_ds = full_ds.map(load_and_preprocess_image)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.956470Z",
     "start_time": "2025-10-01T15:13:48.893372Z"
    }
   },
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data and Creating Batches\n",
    "\n",
    "We will split the dataset into training (80%) and validation (20%) sets. We'll also shuffle the data, create batches, and use prefetching for better performance."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_size = len(image_paths_labels)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Shuffle the dataset for randomness\n",
    "processed_ds = processed_ds.shuffle(buffer_size=dataset_size)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_ds = processed_ds.take(train_size)\n",
    "val_ds = processed_ds.skip(train_size)\n",
    "\n",
    "# Configure the datasets for performance\n",
    "BATCH_SIZE = 128\n",
    "train_ds = train_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"Training dataset: {train_ds}\")\n",
    "print(f\"Validation dataset: {val_ds}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:48.972104Z",
     "start_time": "2025-10-01T15:13:48.956470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: <PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "Validation dataset: <PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Training the Model\n",
    "\n",
    "We will now define and compile a Convolutional Neural Network (CNN) for our image classification task. The model architecture consists of several convolutional blocks to extract features from the images, followed by a dense head to classify them."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = keras.Sequential([\n",
    "keras.Input(shape=(128, 128, 3)),\n",
    "    \n",
    "    # Block 1: Gradually extract features\n",
    "    layers.Conv2D(32, (5,5), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Block 2\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Block 3\n",
    "    layers.Conv2D(128, (5,5), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Classifier Head with SELU\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='selu',\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    layers.AlphaDropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:49.035443Z",
     "start_time": "2025-10-01T15:13:48.974109Z"
    }
   },
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:13:49.051386Z",
     "start_time": "2025-10-01T15:13:49.035443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall()\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:17:56.125269Z",
     "start_time": "2025-10-01T15:13:49.051386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 128\n",
    "\n",
    "# Define callbacks\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"best_model.h5\",   # File to save the model\n",
    "        monitor=\"val_loss\",  # The metric to monitor\n",
    "        save_best_only=True         # Only save when the metric improves\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=32,\n",
    "        restore_best_weights=True   # Restore weights from the epoch with the best F1 score\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# After training, the 'model' object will hold the weights from the\n",
    "# epoch with the lowest val loss, and 'best_model.h5' will also contain that model."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "99/99 [==============================] - 28s 195ms/step - loss: 6.2981 - accuracy: 0.5242 - precision_7: 0.5492 - recall_7: 0.3627 - val_loss: 1.2648 - val_accuracy: 0.5951 - val_precision_7: 0.6054 - val_recall_7: 0.5916\n",
      "Epoch 2/128\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 1.2071 - accuracy: 0.5379 - precision_7: 0.5746 - recall_7: 0.3534 - val_loss: 1.1177 - val_accuracy: 0.5364 - val_precision_7: 0.5250 - val_recall_7: 0.9536\n",
      "Epoch 3/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 1.0528 - accuracy: 0.5820 - precision_7: 0.6077 - recall_7: 0.5037 - val_loss: 0.9943 - val_accuracy: 0.6059 - val_precision_7: 0.5895 - val_recall_7: 0.7481\n",
      "Epoch 4/128\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.9478 - accuracy: 0.6165 - precision_7: 0.6385 - recall_7: 0.5678 - val_loss: 0.9182 - val_accuracy: 0.6437 - val_precision_7: 0.6556 - val_recall_7: 0.6349\n",
      "Epoch 5/128\n",
      "99/99 [==============================] - 8s 85ms/step - loss: 0.8765 - accuracy: 0.6390 - precision_7: 0.6543 - recall_7: 0.6160 - val_loss: 0.8775 - val_accuracy: 0.6614 - val_precision_7: 0.6635 - val_recall_7: 0.6819\n",
      "Epoch 6/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.8157 - accuracy: 0.6549 - precision_7: 0.6663 - recall_7: 0.6445 - val_loss: 0.8278 - val_accuracy: 0.6747 - val_precision_7: 0.6738 - val_recall_7: 0.7017\n",
      "Epoch 7/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.7739 - accuracy: 0.6697 - precision_7: 0.6787 - recall_7: 0.6664 - val_loss: 0.7638 - val_accuracy: 0.6898 - val_precision_7: 0.7157 - val_recall_7: 0.6498\n",
      "Epoch 8/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.7381 - accuracy: 0.6804 - precision_7: 0.6895 - recall_7: 0.6766 - val_loss: 0.7460 - val_accuracy: 0.7053 - val_precision_7: 0.7087 - val_recall_7: 0.7166\n",
      "Epoch 9/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.7145 - accuracy: 0.6895 - precision_7: 0.7004 - recall_7: 0.6810 - val_loss: 0.7449 - val_accuracy: 0.7075 - val_precision_7: 0.6683 - val_recall_7: 0.8465\n",
      "Epoch 10/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.6880 - accuracy: 0.6971 - precision_7: 0.7031 - recall_7: 0.7005 - val_loss: 0.6918 - val_accuracy: 0.7327 - val_precision_7: 0.7287 - val_recall_7: 0.7580\n",
      "Epoch 11/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.6654 - accuracy: 0.7172 - precision_7: 0.7260 - recall_7: 0.7134 - val_loss: 0.6805 - val_accuracy: 0.7548 - val_precision_7: 0.8171 - val_recall_7: 0.6689\n",
      "Epoch 12/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.6618 - accuracy: 0.7184 - precision_7: 0.7267 - recall_7: 0.7159 - val_loss: 0.7120 - val_accuracy: 0.7371 - val_precision_7: 0.7019 - val_recall_7: 0.8422\n",
      "Epoch 13/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.6482 - accuracy: 0.7401 - precision_7: 0.7469 - recall_7: 0.7398 - val_loss: 0.7117 - val_accuracy: 0.7491 - val_precision_7: 0.7041 - val_recall_7: 0.8762\n",
      "Epoch 14/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.6213 - accuracy: 0.7641 - precision_7: 0.7691 - recall_7: 0.7666 - val_loss: 0.6551 - val_accuracy: 0.7943 - val_precision_7: 0.7935 - val_recall_7: 0.8063\n",
      "Epoch 15/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.6434 - accuracy: 0.7592 - precision_7: 0.7637 - recall_7: 0.7629 - val_loss: 0.6733 - val_accuracy: 0.7864 - val_precision_7: 0.7542 - val_recall_7: 0.8620\n",
      "Epoch 16/128\n",
      "99/99 [==============================] - 8s 83ms/step - loss: 0.6461 - accuracy: 0.7835 - precision_7: 0.7834 - recall_7: 0.7940 - val_loss: 0.7095 - val_accuracy: 0.8138 - val_precision_7: 0.8434 - val_recall_7: 0.7797\n",
      "Epoch 17/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.5802 - accuracy: 0.8211 - precision_7: 0.8264 - recall_7: 0.8209 - val_loss: 0.8503 - val_accuracy: 0.7838 - val_precision_7: 0.7276 - val_recall_7: 0.9208\n",
      "Epoch 18/128\n",
      "99/99 [==============================] - 8s 83ms/step - loss: 0.5482 - accuracy: 0.8423 - precision_7: 0.8431 - recall_7: 0.8477 - val_loss: 0.7982 - val_accuracy: 0.8201 - val_precision_7: 0.7975 - val_recall_7: 0.8676\n",
      "Epoch 19/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.5363 - accuracy: 0.8590 - precision_7: 0.8582 - recall_7: 0.8660 - val_loss: 0.7910 - val_accuracy: 0.8321 - val_precision_7: 0.8860 - val_recall_7: 0.7698\n",
      "Epoch 20/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.5190 - accuracy: 0.8781 - precision_7: 0.8810 - recall_7: 0.8792 - val_loss: 0.9263 - val_accuracy: 0.8050 - val_precision_7: 0.7437 - val_recall_7: 0.9425\n",
      "Epoch 21/128\n",
      "99/99 [==============================] - 8s 83ms/step - loss: 0.4849 - accuracy: 0.8973 - precision_7: 0.8994 - recall_7: 0.8986 - val_loss: 0.8040 - val_accuracy: 0.8653 - val_precision_7: 0.8571 - val_recall_7: 0.8830\n",
      "Epoch 22/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.5058 - accuracy: 0.9010 - precision_7: 0.9005 - recall_7: 0.9054 - val_loss: 1.0459 - val_accuracy: 0.8186 - val_precision_7: 0.7588 - val_recall_7: 0.9443\n",
      "Epoch 23/128\n",
      "99/99 [==============================] - 8s 86ms/step - loss: 0.4898 - accuracy: 0.9103 - precision_7: 0.9081 - recall_7: 0.9164 - val_loss: 0.8600 - val_accuracy: 0.8697 - val_precision_7: 0.8805 - val_recall_7: 0.8614\n",
      "Epoch 24/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.4982 - accuracy: 0.9185 - precision_7: 0.9161 - recall_7: 0.9245 - val_loss: 0.9507 - val_accuracy: 0.8583 - val_precision_7: 0.8724 - val_recall_7: 0.8459\n",
      "Epoch 25/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.4816 - accuracy: 0.9211 - precision_7: 0.9186 - recall_7: 0.9271 - val_loss: 0.8888 - val_accuracy: 0.8621 - val_precision_7: 0.8351 - val_recall_7: 0.9090\n",
      "Epoch 26/128\n",
      "99/99 [==============================] - 8s 83ms/step - loss: 0.4860 - accuracy: 0.9272 - precision_7: 0.9236 - recall_7: 0.9341 - val_loss: 0.9491 - val_accuracy: 0.8725 - val_precision_7: 0.8845 - val_recall_7: 0.8626\n",
      "Epoch 27/128\n",
      "99/99 [==============================] - 8s 84ms/step - loss: 0.5036 - accuracy: 0.9283 - precision_7: 0.9250 - recall_7: 0.9350 - val_loss: 1.1698 - val_accuracy: 0.8416 - val_precision_7: 0.7979 - val_recall_7: 0.9233\n",
      "Epoch 28/128\n",
      "30/99 [========>.....................] - ETA: 5s - loss: 0.4793 - accuracy: 0.9380 - precision_7: 0.9364 - recall_7: 0.9421"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 17\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Define callbacks\u001B[39;00m\n\u001B[0;32m      4\u001B[0m callbacks_list \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      5\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(\n\u001B[0;32m      6\u001B[0m         filepath\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_model.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m,   \u001B[38;5;66;03m# File to save the model\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     14\u001B[0m     ),\n\u001B[0;32m     15\u001B[0m ]\n\u001B[1;32m---> 17\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks_list\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1570\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1568\u001B[0m logs \u001B[38;5;241m=\u001B[39m tmp_logs\n\u001B[0;32m   1569\u001B[0m end_step \u001B[38;5;241m=\u001B[39m step \u001B[38;5;241m+\u001B[39m data_handler\u001B[38;5;241m.\u001B[39mstep_increment\n\u001B[1;32m-> 1570\u001B[0m \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n\u001B[0;32m   1572\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py:470\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001B[39;00m\n\u001B[0;32m    464\u001B[0m \n\u001B[0;32m    465\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001B[39;00m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_call_train_batch_hooks:\n\u001B[1;32m--> 470\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mModeKeys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py:317\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook\u001B[1;34m(self, mode, hook, batch, logs)\u001B[0m\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_batch_begin_hook(mode, batch, logs)\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m hook \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 317\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_end_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    320\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized hook: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected values are [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbegin\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    322\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py:340\u001B[0m, in \u001B[0;36mCallbackList._call_batch_end_hook\u001B[1;34m(self, mode, batch, logs)\u001B[0m\n\u001B[0;32m    337\u001B[0m     batch_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_start_time\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times\u001B[38;5;241m.\u001B[39mappend(batch_time)\n\u001B[1;32m--> 340\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_batch_hook_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhook_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_times) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_batches_for_timing_check:\n\u001B[0;32m    343\u001B[0m     end_hook_name \u001B[38;5;241m=\u001B[39m hook_name\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py:388\u001B[0m, in \u001B[0;36mCallbackList._call_batch_hook_helper\u001B[1;34m(self, hook_name, batch, logs)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m    387\u001B[0m     hook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(callback, hook_name)\n\u001B[1;32m--> 388\u001B[0m     \u001B[43mhook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timing:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hook_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hook_times:\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py:1081\u001B[0m, in \u001B[0;36mProgbarLogger.on_train_batch_end\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m-> 1081\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_update_progbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py:1157\u001B[0m, in \u001B[0;36mProgbarLogger._batch_update_progbar\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m   1153\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m add_seen\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1156\u001B[0m     \u001B[38;5;66;03m# Only block async when verbose = 1.\u001B[39;00m\n\u001B[1;32m-> 1157\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[43mtf_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync_to_numpy_or_python_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprogbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseen, \u001B[38;5;28mlist\u001B[39m(logs\u001B[38;5;241m.\u001B[39mitems()), finalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m    632\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\n\u001B[0;32m    633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(t) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m--> 635\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_single_numpy_or_python_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    913\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    914\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 917\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    918\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_to_single_numpy_or_python_type\u001B[39m(t):\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001B[39;00m\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, tf\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m--> 628\u001B[0m         t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;66;03m# as-is.\u001B[39;00m\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, (np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mgeneric)):\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m \n\u001B[0;32m   1136\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1156\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[1;32m-> 1157\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1122\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1124\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric\n",
    "\n",
    "The primary metric for evaluating our model's performance is the **F1-score**. This metric provides a balance between Precision and Recall and is a robust measure for classification tasks.\n",
    "\n",
    "$F1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions for Test Data\n",
    "\n",
    "Now we will use our trained model to make predictions on the test dataset. We'll follow a similar preprocessing pipeline for the test images."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_image_dir = os.path.join(os.getcwd(), \"unzipped_content/test\")\n",
    "\n",
    "## Run this as well if you're on colab ##\n",
    "# test_image_dir = os.path.join(\"content/\", test_image_dir)\n",
    "\n",
    "# Create a list of test image paths, grouped by location ID\n",
    "test_image_paths_by_location = []\n",
    "for index, row in test_data.iterrows():\n",
    "    id = row['rooms']['id']\n",
    "    path = os.path.join(test_image_dir, str(id))\n",
    "    one_location_img_files = os.listdir(path)\n",
    "    one_location_paths = [os.path.join(path, img_path) for img_path in one_location_img_files]\n",
    "    test_image_paths_by_location.append((id, one_location_paths))\n",
    "\n",
    "print(\"Number of locations in test data with image paths:\", len(test_image_paths_by_location))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:19:36.413424Z",
     "start_time": "2025-10-01T15:19:36.325810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of locations in test data with image paths: 861\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "source": [
    "# Flatten the list to get all image paths and their corresponding IDs\n",
    "test_image_paths = []\n",
    "test_ids = []\n",
    "for location_id, paths in test_image_paths_by_location:\n",
    "    test_image_paths.extend(paths)\n",
    "    test_ids.extend([location_id] * len(paths))\n",
    "\n",
    "# Create a TensorFlow dataset for test images\n",
    "test_path_ds = tf.data.Dataset.from_tensor_slices(test_image_paths)\n",
    "\n",
    "# Preprocess the test images\n",
    "def preprocess_test_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    img = img\n",
    "    return img\n",
    "\n",
    "processed_test_ds = test_path_ds.map(preprocess_test_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch the test dataset\n",
    "test_ds_batched = processed_test_ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Test dataset ready for prediction.\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:19:40.817021Z",
     "start_time": "2025-10-01T15:19:40.726661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset ready for prediction.\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_ds_batched)\n",
    "\n",
    "# Convert probabilities to boolean labels (True/False)\n",
    "predicted_labels = (predictions > 0.5).flatten()\n",
    "\n",
    "print(f\"Number of predictions made: {len(predicted_labels)}\")\n",
    "print(\"First 15 predicted labels:\", predicted_labels[:15])"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:19:48.197435Z",
     "start_time": "2025-10-01T15:19:44.098087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 4s 58ms/step\n",
      "Number of predictions made: 8505\n",
      "First 15 predicted labels: [False  True False False  True  True False False  True False False False\n",
      " False False False]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "source": [
    "# Since there are multiple images per location, we need to aggregate the predictions.\n",
    "# Strategy: A location has a pool if the *majority* of its images are predicted to have a pool.\n",
    "\n",
    "# Create a dictionary to store predictions for each location ID\n",
    "location_predictions = {}\n",
    "for i, label in enumerate(predicted_labels):\n",
    "    location_id = test_ids[i]\n",
    "    if location_id not in location_predictions:\n",
    "        location_predictions[location_id] = []\n",
    "    location_predictions[location_id].append(label)\n",
    "\n",
    "# Aggregate predictions by location using a majority vote\n",
    "final_predictions = {}\n",
    "for location_id, preds in location_predictions.items():\n",
    "    num_true = sum(preds)\n",
    "    num_false = len(preds) - num_true\n",
    "    if num_true >= num_false:\n",
    "        final_predictions[location_id] = True\n",
    "    else:\n",
    "        final_predictions[location_id] = False\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame(list(final_predictions.items()), columns=['id', 'pool'])\n",
    "\n",
    "print(submission.head())\n",
    "print(f\"\\nSubmission DataFrame shape: {submission.shape}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:19:50.292420Z",
     "start_time": "2025-10-01T15:19:50.261060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id   pool\n",
      "0  3160664  False\n",
      "1  3195184  False\n",
      "2  3224078   True\n",
      "3  3233712   True\n",
      "4  3201449   True\n",
      "\n",
      "Submission DataFrame shape: (861, 2)\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Submission File\n",
    "\n",
    "After feature engineering and modeling, you have an algorithm that can predict the target variable from the independent variables. Use this model to predict the samples in the test data and prepare the results in the following DataFrame format.\n",
    "\n",
    "| Column | Description                               |\n",
    "|--------|-------------------------------------------|\n",
    "| `pool` | Predicted presence of a pool (True/False) |\n",
    "| `id`   | Unique identifier of the accommodation    |\n",
    "\n",
    "The DataFrame must be named `submission`, otherwise, the evaluation system cannot assess your work. It should contain two columns, `id` and `pool`, and have one row for each unique ID in the test set. Below is an example of the first 5 rows of the `submission` DataFrame. Your predicted values in the `pool` column may differ.\n",
    "\n",
    "| id      | pool  |\n",
    "|---------|-------|\n",
    "| 3160664 | True  |\n",
    "| 3195184 | False |\n",
    "| 3224078 | False |\n",
    "| 3233712 | True  |\n",
    "| 3201449 | True  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission Archive\n",
    "\n",
    "Run the following cell to create the `result.zip` file. Ensure that you have saved the notebook (`Ctrl+S`) before running this cell. If you are using Google Colab, download the latest version of your notebook and include it in the `result.zip` file before submission."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Save the submission dataframe to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Define the files to be included in the zip archive\n",
    "notebook_name = 'Pool_Detector_English.ipynb' # Make sure this matches your notebook's filename\n",
    "file_names = [notebook_name, 'submission.csv']\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"Files to be zipped:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            if os.path.exists(file_name):\n",
    "                 zf.write(file_name, compress_type=compression)\n",
    "            else:\n",
    "                print(f\"Warning: {file_name} not found and will not be included in the zip file.\")\n",
    "\n",
    "compress(file_names)\n",
    "print(\"\\nresult.zip created successfully.\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:19:58.131453Z",
     "start_time": "2025-10-01T15:19:58.105694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to be zipped:\n",
      "['Pool_Detector_English.ipynb', 'submission.csv']\n",
      "Warning: Pool_Detector_English.ipynb not found and will not be included in the zip file.\n",
      "\n",
      "result.zip created successfully.\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": [
    "# Optional: Save the trained model for future use\n",
    "model.save('pool_detector_model.h5')"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:20:00.408044Z",
     "start_time": "2025-10-01T15:20:00.277041Z"
    }
   },
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
